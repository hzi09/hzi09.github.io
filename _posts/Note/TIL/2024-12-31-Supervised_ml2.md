---
title:  "[TIL] ë‚´ì¼ë°°ì›€ìº í”„ 36ì¼ì°¨_[ML] ch2.ê°œì¸ê³¼ì œ - 1. ì§€ë„í•™ìŠµ(ë„ì „ê³¼ì œ)" 

categories: 
    - TIL
tags: 
    - TIL
    - ë‚´ì¼ë°°ì›€ìº í”„
    - ë¨¸ì‹ ëŸ¬ë‹
    - ì§€ë„í•™ìŠµ


toc: True
toc_sticky: True
---

![TIL](/assets/images/TIL2.png){: .align-center style="width:35%;"}

# ğŸ‘€Today I Learn
## ëª¨ë¸ ì•™ìƒë¸”
- ë°°ê¹… ëª¨ë¸ê³¼ ë¶€ìŠ¤íŒ… ëª¨ë¸ì„ ì¶”ê°€í•œ í›„(ì—¬ê¸°ì„œëŠ” ì½”ë“œ ìƒëµ), ê°€ì¤‘ í‰ê·  ì•™ìƒë¸”ì„ ì§„í–‰
  - ê°€ì¤‘ ì•™ìƒë¸” : ì„±ëŠ¥ì´ ë†’ì€ ëª¨ë¸ 5ê°œë¥¼ ì„ íƒ
    ```python
    # r2ì ìˆ˜ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    model_pred = [y_lr_pred, y_pr_pred, y_tree_pred, y_rf_pred, y_ri_pred, y_ls_pred, y_bagging_pred, y_boosting_pred]
    model_r2_score = [lr_r2, pr_r2, tree_r2, rf_r2, ri_r2, ls_r2, bagging_r2, boosting_r2]

    print(model_r2_score)

    # ì„±ëŠ¥ì´ ë†’ì€ 5ê°œ ëª¨ë¸ ì„ íƒ
    top_models_idx = np.argsort(model_r2_score)[-5:]  # ìƒìœ„ 5ê°œ ëª¨ë¸ ì¸ë±ìŠ¤
    top_pred = [model_pred[i] for i in top_models_idx]
    top_scores = [model_r2_score[i] for i in top_models_idx]

    # ê°€ì¤‘ì¹˜ ê³„ì‚° (ì„±ëŠ¥ ê¸°ë°˜)
    weights = np.array(top_scores) / sum(top_scores)

    # ê°€ì¤‘ í‰ê·  ì•™ìƒë¸”
    final_pred = sum(w * pred for w, pred in zip(weights, top_pred))
    
    # ì„±ëŠ¥í‰ê°€
    final_mae = mean_absolute_error(y_test, final_pred)
    final_mse = mean_squared_error(y_test, final_pred)
    final_r2 = r2_score(y_test, final_pred)

    print(f'Mean Absolute Error (MAE) : {final_mae}')
    print(f'Mean Squared Error (MSE) : {final_mse}')
    print(f'RÂ² Score : {final_r2}')
    ```
  - ê²°ê³¼
    ```
    Mean Absolute Error (MAE) : 1.920664657312724
    Mean Squared Error (MSE) : 6.670866427584049
    RÂ² Score : 0.8636510323472387
    ```

- ë¼ì˜ ëª¨ë¸ë³´ë‹¤ ê²°ê³¼ê°€ ë‚®ê²Œ ë‚˜ì˜´
  - ì•„ë§ˆ ê°€ì¤‘ì¹˜ ë¶€ì—¬ë¥¼ í•˜ì§€ ì•Šì•„ì„œê°€ ì•„ë‹ê¹Œ ì‹¶ì€ë° ì´ ë¶€ë¶„ì€ ì¶”ê°€ í•™ìŠµ í›„ì— ë‹¤ì‹œ ìˆ˜ì •ì´ í•„ìš”í•  ê²ƒ ê°™ìŒ


    |                           | ì„ í˜•íšŒê·€ | ë‹¤í•­íšŒê·€ | ì˜ì‚¬ê²°ì •ë‚˜ë¬´ | ëœë¤í¬ë ˆìŠ¤íŠ¸ | ë¦¬ì§€íšŒê·€ | ë¼ì˜íšŒê·€ | ë°°ê¹…ëª¨ë¸ | ë¶€ìŠ¤íŒ…ëª¨ë¸ | ê°€ì¤‘í‰ê· ì•™ìƒë¸” |
    |--------------------------:|---------:|---------:|-------------:|-------------:|---------:|---------:|---------:|-----------:|-----------------:|
    | Mean Absolute Error (MAE) |   2.4453 |   2.1346 |       2.6892 |       1.9230 |   2.4510 |   1.8711 |   1.9380 |     1.9168 |           1.9206 |
    |  Mean Squared Error (MSE) |  13.0004 |   8.7704 |      13.7651 |       6.3052 |  13.0244 |   5.9593 |   6.3964 |     6.4878 |           6.6708 |
    |                  RÂ² Score |   0.7342 |   0.8207 |       0.7186 |       0.8711 |   0.7337 |   0.8781 |   0.8692 |     0.8673 |           0.8636 |


## í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹

- ëœë¤í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ì„ ì´ìš©í•˜ì—¬ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì§„í–‰
  - ê·¸ë¦¬ë“œ ì„œì¹˜
    ```python
    from sklearn.model_selection import GridSearchCV

    # í•˜ì´í¼íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì„¤ì •
    param_grid = {
        'n_estimators': [300], 
        'max_depth': [3, 5, 7, 10], 
        'min_samples_split': [6 ,8, 12, 18],
        'min_samples_leaf': [6, 8, 16, 20],
    }


    rf_clf = RandomForestRegressor(random_state=0, n_jobs=-1) # n_jobs = -1 : ëª¨ë“  CPU ì½”ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµ
    grid_cv = GridSearchCV(rf_clf, param_grid=param_grid, cv=5, n_jobs=-1)
    grid_cv.fit(X_train, y_train)

    # ë°ì´í„° ë¶„í•  (í›ˆë ¨ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # ë°ì´í„° ìŠ¤ì¼€ì¼ë§
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    # ìµœì  ëª¨ë¸ë¡œ ì˜ˆì¸¡
    best_rf_model = RandomForestRegressor(n_estimators=300, max_depth=10, min_samples_leaf=6, min_samples_split=6)
    best_rf_model.fit(X_train_scaled, y_train)
    y_rf_pred = best_rf_model.predict(X_test_scaled)

    # ëª¨ë¸ í‰ê°€
    rf_mae = mean_absolute_error(y_test, y_rf_pred)
    rf_mse = mean_squared_error(y_test, y_rf_pred)
    rf_r2 = r2_score(y_test, y_rf_pred)

    print(f'Mean Absolute Error (MAE): {rf_mae}')
    print(f'Mean Squared Error (MSE): {rf_mse}')
    print(f'RÂ² Score: {rf_r2}')
    ```

- ëœë¤ ì„œì¹˜
    ```python
    from sklearn.model_selection import RandomizedSearchCV

    # í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¶„í¬ ì„¤ì •
    param_dist = {
        'n_estimators': [300],
        'max_depth': [5, 7, 10, 15], 
        'min_samples_split': [4 ,6 ,8, 12],
        'min_samples_leaf': [6, 8, 16, 20],
        'bootstrap': [True, False]
    }


    rf_clf = RandomForestRegressor(random_state=0, n_jobs=-1) # n_jobs = -1 : ëª¨ë“  CPU ì½”ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµ
    random_cv = RandomizedSearchCV(rf_clf, param_distributions=param_dist, cv=5, n_jobs=-1)
    random_cv.fit(X_train, y_train)

    # ë°ì´í„° ë¶„í•  (í›ˆë ¨ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # ë°ì´í„° ìŠ¤ì¼€ì¼ë§
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    # ìµœì  ëª¨ë¸ë¡œ ì˜ˆì¸¡
    best_rf_model = RandomForestRegressor(n_estimators=300, max_depth=7, min_samples_leaf=6, min_samples_split=4, bootstrap=True)
    best_rf_model.fit(X_train_scaled, y_train)
    y_rf_pred = best_rf_model.predict(X_test_scaled)

    # ëª¨ë¸ í‰ê°€
    rf_mae = mean_absolute_error(y_test, y_rf_pred)
    rf_mse = mean_squared_error(y_test, y_rf_pred)
    rf_r2 = r2_score(y_test, y_rf_pred)

    print(f'Mean Absolute Error (MAE): {rf_mae}')
    print(f'Mean Squared Error (MSE): {rf_mse}')
    print(f'RÂ² Score: {rf_r2}')
    ```

- ê²°ê³¼
  - í•˜ì´í¼ íŒŒë¼ë¯¸í„°ë¥¼ ì§„í–‰í–ˆì§€ë§Œ ê·¸ë¦¬ë“œì„œì¹˜ ëœë¤ì„œì¹˜ ë‘ê°œ ëª¨ë‘ RÂ²ê°€ ë–¨ì–´ì§„ê±¸ í™•ì¸
  - ì´ ë¶€ë¶„ë„ í•™ìŠµì´ ì¡°ê¸ˆ ë” í•„ìš”

    |                           | ëœë¤í¬ë ˆìŠ¤íŠ¸ | ê·¸ë¦¬ë“œì„œì¹˜ | ëœë¤ì„œì¹˜ |
    |--------------------------:|-------------:|-----------:|---------:|
    | Mean Absolute Error (MAE) |       1.9230 |     2.0244 |   2.0240 |
    |  Mean Squared Error (MSE) |       6.3052 |     8.1637 |   8.0601 |
    |                  RÂ² Score |       0.8711 |     0.8331 |   0.8352 | 


## ì‹œê°„ì  ìš”ì†Œ ì¶”ê°€
- ë°ì´í„° ì „ì²˜ë¦¬ í›„ì— ì‹œê°„ì  ìš”ì†Œë¥¼ ì¶”ê°€
  - ì–´ë–¤ ìš”ì†Œê°€ ê°€ì¥ ì í•©í• ì§€ ìƒê°í•œ ëì— `TAX`ë¡œ ê²°ì • (TAX: 10,000ë‹¬ëŸ¬ë‹¹ ì¬ì‚°ì„¸ìœ¨)
- `TAX`ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„° ì •ë ¬
    ```python
    # ì´ìƒì¹˜ê°€ ì²˜ë¦¬ëœ housing ë°ì´í„°ì—ì„œ TAX ê°’ìœ¼ë¡œ ë°ì´í„° ì •ë ¬
    housing_processed = housing_processed.sort_values(by="TAX").reset_index(drop=True)
    housing_processed
    ```
- `TAX`ê°€ ì˜¬ë¼ê°ˆë•Œë§ˆë‹¤ 1ì´ ì˜¬ë¼ê°€ëŠ” ë°©í–¥ìœ¼ë¡œ ì§„í–‰
  - ì‹¤ì œ ë…„ë„ë¥¼ ì•Œ ìˆ˜ ì—†ì–´ ë°ì´í„°ë¥¼ êµ¬ë¶„í•˜ê¸° ìœ„í•´ 1ì”© ì¦ê°€í•˜ëŠ” ê²ƒìœ¼ë¡œ í‘œí˜„í•¨
  - ë¬¼ë¡  ì„¸ê¸ˆì´ ë–¨ì–´ì§ˆë•Œë„ ìˆì–´ ì´ ë°ì´í„°ë¥¼ ì‹œê°„ë°ì´í„°ë¡œ ë°”ê¾¸ëŠ” ê²ƒì€ ì˜¬ë°”ë¥´ì§€ ì•Šì€ ì„ íƒì¼ìˆ˜ë„ ìˆìŒ
    ```python
    # TAXê°’ì´ ì˜¬ë¼ê°ˆë•Œë§ˆë‹¤ 1ì„ ë”í•˜ì—¬ ì‹œê°„ì˜ íë¦„ì„ í‘œí˜„
    housing_processed['TIME'] = (housing_processed['TAX'] != housing_processed['TAX'].shift()).cumsum()
    housing_processed
    ```
- `MEDV`ì™€ -0.51ë¡œ ìƒê´€ê´€ê³„ê°€ ë†’ì€ ê²ƒìœ¼ë¡œ í™•ì¸
- ê²°ê³¼ ë¹„êµ
  - ê¸°ì¡´ ê²°ê³¼

    |                           | ì„ í˜•íšŒê·€ | ë‹¤í•­íšŒê·€ | ì˜ì‚¬ê²°ì •ë‚˜ë¬´ | ëœë¤í¬ë ˆìŠ¤íŠ¸ | ë¦¬ì§€íšŒê·€ | ë¼ì˜íšŒê·€ | ë°°ê¹…ëª¨ë¸ | ë¶€ìŠ¤íŒ…ëª¨ë¸ | ê°€ì¤‘í‰ê· ì•™ìƒë¸” |
    |--------------------------:|---------:|---------:|-------------:|-------------:|---------:|---------:|---------:|-----------:|-----------------:|
    | Mean Absolute Error (MAE) |   2.4453 |   2.1346 |       2.6892 |       1.9230 |   2.4510 |   1.8711 |   1.9380 |     1.9168 |           1.9206 |
    |  Mean Squared Error (MSE) |  13.0004 |   8.7704 |      13.7651 |       6.3052 |  13.0244 |   5.9593 |   6.3964 |     6.4878 |           6.6708 |
    |                  RÂ² Score |   0.7342 |   0.8207 |       0.7186 |       0.8711 |   0.7337 |   0.8781 |   0.8692 |     0.8673 |           0.8636 |
    
  - `TAX` ì¶”ê°€ ê²°ê³¼

    |                           | ì„ í˜•íšŒê·€ | ë‹¤í•­íšŒê·€ | ì˜ì‚¬ê²°ì •ë‚˜ë¬´ | ëœë¤í¬ë ˆìŠ¤íŠ¸ | ë¦¬ì§€íšŒê·€ | ë¼ì˜íšŒê·€ | ë°°ê¹…ëª¨ë¸ | ë¶€ìŠ¤íŒ…ëª¨ë¸ | ê°€ì¤‘ í‰ê·  ì•™ìƒë¸” |
    |--------------------------:|---------:|---------:|-------------:|-------------:|---------:|---------:|---------:|-----------:|-----------------:|
    | Mean Absolute Error (MAE) |   2.8446 |   2.1745 |       2.6267 |       2.0439 |   2.8482 |   3.3502 |   2.0510 |     1.9960 |           1.9760 |
    |  Mean Squared Error (MSE) |  13.6133 |  10.8285 |      11.5584 |       7.5495 |  13.6438 |  17.2110 |   7.6402 |     7.7054 |           7.1979 |
    |                  RÂ² Score |   0.8076 |   0.8469 |       0.8366 |       0.8933 |   0.8072 |   0.7568 |   0.8920 |     0.8911 |           0.8982 |

  - ìƒê°í•˜ê¸°ì—ëŠ” ë„ˆë¬´ ìƒê´€ê´€ê³„ê°€ ì¡°ê¸ˆ ìˆëŠ” ë°ì´í„°ê°€ ë“¤ì–´ì˜¤ë©´ì„œ RÂ²ê°€ ë†’ì•„ì§„ê²Œ ì•„ë‹Œê°€ ìƒê°ì´ ë“ ë‹¤(ë¬¼ë¡  ë‚®ì•„ì§„ ë°ì´í„°ë„ ìˆìŒ)
  - MAEì™€ MSEê°€ ë‚®ì•„ì§€ì§€ ì•Šê³  ìƒìŠ¹í–ˆìœ¼ë¯€ë¡œ ì¢‹ì€ ëª¨ë¸ì´ë¼ê³  íŒë‹¨í•˜ê¸°ì—ëŠ” ì–´ë ¤ìš¸ ê²ƒ ê°™ë‹¤.


<br>
<br>


# ğŸ’¡Today I Thought

## ì˜¤ëŠ˜ì˜ ì²´í¬ë¦¬ìŠ¤íŠ¸
- [x]  ì•Œê³ ë¦¬ì¦˜ ì½”ë“œì¹´íƒ€ 44-46
- [x]  SQL ì½”ë“œì¹´íƒ€ 49-50
- [x]  ë°±ì¤€ ì½”ë”©í…ŒìŠ¤íŠ¸ 1ë¬¸ì œ
- [x]  ë¨¸ì‹ ëŸ¬ë‹ ê³¼ì œ ì œì¶œí•˜ê¸°
- [ ]  ì¥ê³  15ê°•ê¹Œì§€ ë“£ê¸°
- [x]  TIL ì‘ì„±

## íšŒê³ 
&nbsp; ì˜¤ëŠ˜ ë°ê¸€ë°ì´ë¼ì„œ ë„íŒŒë¯¼ì´ í„°ì¡Œë”ë‹ˆ ì¥ê³  ê°•ì˜ë¥¼ ëê¹Œì§€ ëª»ë“¤ì—ˆë‹¤.. ë„íŒŒë¯¼ì˜ ë…¸ì˜ˆ.. ì´ë˜ì €ë˜ ë°”ì˜ê³ , ìš°ìš¸í–ˆë‹¤ê°€ í–‰ë³µí–ˆë˜ í•œ í•´ê°€ ì €ë¬¼ê³  ìƒˆë¡œìš´ í•œ í•´ê°€ ì‹œì‘ëœë‹¤. ì˜ˆì „ì—” í•œ ì‚´ ë¨¹ëŠ”ê²Œ ì •ë§ ì»¸ëŠ”ë°, ì§€ê¸ˆì€ ê·¸ëƒ¥ í˜ëŸ¬ê°€ëŠ” ë‚ ì§œ ì¤‘ì— í•˜ë‚˜ì¸ ê¸°ë¶„. ë‚¨ì€ ë¶€íŠ¸ìº í”„ ê¸°ê°„ì—ë„ í˜ë‚´ì•¼ì§€! í™”ì´íŒ…!