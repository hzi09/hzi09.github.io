---
title:  "[TIL] 내일배움캠프 00일차_[DL] 특이값 분해(Singular Value Decomposition, SVD)" 

categories: 
    - TIL
tags: 
    - TIL
    - 내일배움캠프
    - 머신러닝
    - SVD


toc: True
toc_sticky: True
---

![TIL](/assets/images/TIL2.png){: .align-center style="width:35%;"}

# 👀Today I Learn
## 특이값 분해(SVD)란?
- 특이값 분해(Singular Value Decomposition, SVD)는 행렬을 세 개의 행렬로 분해하는 기법으로, 차원 축소, 데이터 압축, 노이즈 제거 등 다양한 머신러닝 응용에 사용됨
- 특히, 선형 대수와 머신러닝에서 중요한 개념 중 하나로, 데이터의 구조를 분석하고 변환하는 데 널리 활용
- SVD는 임의의 m × n 행렬 를 다음과 같이 분해

$$ A = U \sum{V^T} $$

- 여기서
  - U : $m × n$직교 행렬 (좌측 특이 벡터, 의 고유 벡터). 각 열은 정규화된 직교 벡터이며, 입력 데이터의 주요 방향을 나타냄

  - Σ :  대각 행렬 (특이값을 대각 원소로 가짐). 대각선 원소는 행렬 의 중요한 정보량을 나타내는 값으로, 가장 큰 특이값이 가장 중요한 방향을 나타냄

  - V:  직교 행렬 (우측 특이 벡터, 의 고유 벡터). 각 행은 데이터 차원에 대한 변환 방향을 나타냄
- 이러한 분해를 통해 데이터의 주요 구조를 추출할 수 있으며, 차원 축소, 추천 시스템, 문서 주제 분석 등에 효과적으로 활용됨

<br>

## SVD의 직관적인 이해

- SVD는 데이터를 다양한 방향으로 변환하여 정보가 가장 많이 포함된 부분을 찾는 과정으로 볼 수 있음
- 예를 들어:
  - 원래 데이터가 m × n 크기의 행렬이라면, SVD를 통해 데이터를 다양한 축으로 분해하여 가장 중요한 정보(특이값이 큰 축)를 보존하면서 불필요한 정보(특이값이 작은 축)를 제거할 수 있음
  - 데이터의 차원을 줄이는 데 유용하며, 특히 PCA(주성분 분석)와 밀접한 연관이 있음

- SVD는 특히 희소 행렬이나 고차원 데이터에서 중요한 패턴을 추출하는 데 유용
- 특이값이 작은 축을 제거하면 원본 데이터의 중요한 정보만 남게 되어 차원 축소 및 데이터 압축 효과를 얻을 수 있음

<br>

## SVD의 활용 사례
### 차원 축소(Dimensionality Reduction)
- PCA(주성분 분석, Principal Component Analysis)도 SVD를 기반으로 작동하며, 고차원 데이터를 저차원으로 변환하는 데 사용됨
- 주어진 데이터의 주요 축을 찾아 차원을 줄이면서도 최대한 많은 정보를 유지할 수 있도록 도와줌

### 추천 시스템(Recommendation Systems)
- SVD는 넷플릭스, 아마존, 유튜브 등의 추천 시스템에서 사용자-아이템 행렬을 분해하여 유사한 사용자나 항목을 찾는 데 활용됨
  - 사용자의 선호도를 행렬 형태로 표현한 후, SVD를 이용하여 잠재적인 패턴을 추출
  - 특이값을 이용하여 사용자와 아이템 간의 관계를 파악하고, 기존에 보지 않은 콘텐츠를 추천하는 데 활용됨

### 이미지 압축 (Image Compression)
- 이미지는 보통 픽셀 값의 행렬로 표현됨
  - SVD를 적용하여 행렬을 세 개의 작은 행렬로 분해하면, 일부 특이값만 사용하여 원본 이미지에 가까운 형태를 재구성할 수 있음
  - 이를 통해 데이터의 손실을 최소화하면서도 저장 공간을 절약할 수 있음

<br>

## SVD 예제
### Iris 데이터셋 차원 축소

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn import datasets

# Iris 데이터셋 로드
iris = datasets.load_iris()
X = iris.data  # 특성 행렬
y = iris.target  # 레이블

# 데이터 평균 중심화
X_centered = X - np.mean(X, axis=0)

# SVD 수행
U, S, VT = np.linalg.svd(X_centered)

# 첫 두 개의 특이값에 해당하는 성분 선택
X_reduced = np.dot(X_centered, VT.T[:, :2])

# 시각화
plt.figure(figsize=(8, 6))
for target, color, label in zip([0, 1, 2], ['r', 'g', 'b'], iris.target_names):
    plt.scatter(X_reduced[y == target, 0], X_reduced[y == target, 1], c=color, label=label)
plt.xlabel('첫 번째 주성분')
plt.ylabel('두 번째 주성분')
plt.legend()
plt.title('Iris 데이터셋의 SVD 기반 2D 시각화')
plt.show()
```
- 코드 설명
  - Iris 데이터셋 로드: 네 개의 특성(꽃잎 길이, 꽃잎 너비 등)과 세 개의 붓꽃 품종을 포함
  - 데이터 평균 중심화: 데이터를 평균이 0이 되도록 변환하여 중심을 맞춤
  - SVD 수행: 행렬을 분해하여 주요 성분을 추출
  - 2차원으로 축소: 가장 중요한 두 개의 축을 선택하여 차원을 줄임
  - 시각화: 세 가지 붓꽃 품종을 서로 다른 색상으로 표현하여 차원이 축소된 결과를 확인

- 결과

    ![Image](https://github.com/user-attachments/assets/1a0251c2-0206-47e4-a28d-8b5af454d376)

<br>
<br>

# 💡Today I Thought

## 오늘의 체크리스트
- [x]  알고리즘 코드카타 1문제
- [x]  SQL 코드카타 1문제
- [x]  Steam API를 활용한 데이터 수집
- [x]  SVD 공부
- [x]  TIL 제출

## 회고
&nbsp;데이터 수집도 어려워.. 어제 켜놓고 잤는데 7천개 이후에 멈춰있었던.. 너무 충격과 공포였다..😶‍🌫️ 휴.. 내일의 나에게 넘기고.. 오늘은 쉴래...🫠