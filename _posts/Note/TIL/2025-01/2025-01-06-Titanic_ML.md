---
title:  "[TIL] ë‚´ì¼ë°°ì›€ìº í”„ 42ì¼ì°¨_[ML] Titanic ë°ì´í„°ë¥¼ ì‚¬ìš©í•œ ë¨¸ì‹ ëŸ¬ë‹(1)" 

categories: 
    - TIL
tags: 
    - TIL
    - ë‚´ì¼ë°°ì›€ìº í”„
    - ë¨¸ì‹ ëŸ¬ë‹


toc: True
toc_sticky: True
---

![TIL](/assets/images/TIL2.png){: .align-center style="width:35%;"}

# ğŸ‘€Today I Learn
## íƒ€ì´íƒ€ë‹‰ ë°ì´í„° í™•ì¸
* Passengerid: íƒ‘ìŠ¹ì ë°ì´í„° ì¼ë ¨ë²ˆí˜¸
* survived: ìƒì¡´ ì—¬ë¶€, 0 = ì‚¬ë§, 1 = ìƒì¡´
* Pclass: í‹°ì¼“ì˜ ì„ ì‹¤ ë“±ê¸‰, 1 = ì¼ë“±ì„, 2 = ì´ë“±ì„, 3 = ì‚¼ë“±ì„
* sex: íƒ‘ìŠ¹ì ì„±ë³„
* name: íƒ‘ìŠ¹ì ì´ë¦„
* Age: íƒ‘ìŠ¹ì ë‚˜ì´
* sibsp: ê°™ì´ íƒ‘ìŠ¹í•œ í˜•ì œìë§¤ ë˜ëŠ” ë°°ìš°ì ì¸ì›ìˆ˜
* parch: ê°™ì´ íƒ‘ìŠ¹í•œ ë¶€ëª¨ë‹˜ ë˜ëŠ” ì–´ë¦°ì´ ì¸ì›ìˆ˜
* ticket: í‹°ì¼“ ë²ˆí˜¸
* fare: ìš”ê¸ˆ
* cabin: ì„ ì‹¤ ë²ˆí˜¸
* embarked: ì¤‘ê°„ ì •ì°© í•­êµ¬ C = Cherbourg, Q = Queenstown, S = Southampton


### ë°ì´í„° ë¡œë“œ
- ë°ì´í„°ë¥¼ ì•Œì•„ì•¼ ë¨¸ì‹ ëŸ¬ë‹ì„ ì‹œì‘í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê³  ë°ì´í„°ë¥¼ í™•ì¸í•˜ëŠ” ê³¼ì •ì„ ê±°ì¹¨
    ```python
    import numpy as np
    import pandas as pd

    df = pd.read_csv('./titanic.csv')

    print('Train ë°ì´í„° ì •ë³´')
    print(df.info())
    df.head(3)
    ```
  - ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
    - Pandas ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ `read_csv()`ë¥¼ í†µí•´ CSV íŒŒì¼ì˜ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜´
  - ë°ì´í„° ì •ë³´ í™•ì¸í•˜ê¸°
    - `info()`ë¥¼ ì‚¬ìš©í•˜ë©´ ì»¬ëŸ¼, Null ê°’ì´ ì•„ë‹Œ ë°ì´í„° ê°¯ìˆ˜, ë°ì´í„° íƒ€ì… ë“±ì„ í™•ì¸ê°€ëŠ¥
  - ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
    - `head()`ë¥¼ ì‚¬ìš©í•˜ë©´ ë°ì´í„°ë¥¼ ë¯¸ë¦¬ë³¼ ìˆ˜ ìˆìŒ!
    - ê¸°ë³¸ê°’ì€ 5ê°œì´ì§€ë§Œ ë‚´ê°€ ì…‹íŒ…í•œë§Œí¼ í™•ì¸ ê°€ëŠ¥

- ê²°ê³¼
    ```
    Train ë°ì´í„° ì •ë³´
    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 891 entries, 0 to 890
    Data columns (total 12 columns):
    #   Column       Non-Null Count  Dtype  
    ---  ------       --------------  -----  
    0   PassengerId  891 non-null    int64  
    1   Survived     891 non-null    int64  
    2   Pclass       891 non-null    int64  
    3   Name         891 non-null    object 
    4   Sex          891 non-null    object 
    5   Age          714 non-null    float64
    6   SibSp        891 non-null    int64  
    7   Parch        891 non-null    int64  
    8   Ticket       891 non-null    object 
    9   Fare         891 non-null    float64
    10  Cabin        204 non-null    object 
    11  Embarked     889 non-null    object 
    dtypes: float64(2), int64(5), object(5)
    memory usage: 83.7+ KB
    None
    ```

    |   | PassengerId | Survived | Pclass |                                              Name |    Sex |  Age | SibSp | Parch |           Ticket |    Fare | Cabin | Embarked |
    |:-:|------------:|---------:|-------:|--------------------------------------------------:|-------:|-----:|------:|------:|-----------------:|--------:|------:|---------:|
    | 0 |           1 |        0 |      3 |                           Braund, Mr. Owen Harris |   male | 22.0 |     1 |     0 |        A/5 21171 |  7.2500 |   NaN |        S |
    | 1 |           2 |        1 |      1 | Cumings, Mrs. John Bradley (Florence Briggs Th... | female | 38.0 |     1 |     0 |         PC 17599 | 71.2833 |   C85 |        C |
    | 2 |           3 |        1 |      3 |                            Heikkinen, Miss. Laina | female | 26.0 |     0 |     0 | STON/O2. 3101282 |  7.9250 |   NaN |        S |

<br>

## ë°ì´í„° ì „ì²˜ë¦¬
### ê²°ì¸¡ì¹˜ ì²˜ë¦¬
- Age : í‰ê·  ê°’ìœ¼ë¡œ ì±„ìš°ê¸°
- Cabin : Nìœ¼ë¡œ ì±„ìš°ê¸°
- Embarked : Nìœ¼ë¡œ ì±„ìš°ê¸°

```python
def fillna(df):
    df['Age'] = df['Age'].fillna(df['Age'].mean())
    df['Cabin'] = df['Cabin'].fillna('N')
    df['Embarked'] = df['Embarked'].fillna('N')
    return df
```

<br>

### í•„ìš” ì—†ëŠ” ì»¬ëŸ¼ ì œê±°
- PassengerId
- Name
- Ticket

```python
def drop_features(df):
    return df.drop(['PassengerId', 'Name', 'Ticket'], axis=1)
```

<br>

### ë²”ì£¼í˜• ë°ì´í„° ì²˜ë¦¬
- Sex : ìˆ«ìí˜• ë³€í™˜
- Embarked : ìˆ«ìí˜• ë³€í™˜
- Cabin : ì²« ë²ˆì§¸ ë¬¸ìë§Œ ì¶”ì¶œ í›„ ìˆ«ìí˜• ë³€í™˜

```python
from sklearn.preprocessing import LabelEncoder

def format_features(df):
    df['Cabin'] = df['Cabin'].astype(str).str[:1]
    features = ['Cabin', 'Sex', 'Embarked']
    for feature in features:
        le = LabelEncoder()
        df[feature] = le.fit_transform(df[feature])
    return df
```

<br>

### ë°ì´í„° ì „ì²˜ë¦¬ í•¨ìˆ˜
- ìœ„ì—ì„œ ë§Œë“  ì„¸ê°œì˜ í•¨ìˆ˜ë¥¼ í•˜ë‚˜ì˜ í•¨ìˆ˜ë¡œ ë§Œë“¤ì–´ì¤Œ
  - ê²°ì¸¡ì¹˜ ì²˜ë¦¬ í•¨ìˆ˜
  - í•„ìš”ì—†ëŠ” ì»¬ëŸ¼ ì œê±° í•¨ìˆ˜
  - ë²”ì£¼í˜• ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜

```python
def transform_features(df):
    df = fillna(df)
    df = drop_features(df)
    df = format_features(df)
    return df
```

<br>

## ë°ì´í„° ë¶„ë¦¬
- ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ë¡œ ë°ì´í„°ë¥¼ í•™ìŠµ/ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ ë°ì´í„°ì…‹ì„ ë¶„ë¦¬
  - ì‚¬ì´í‚·ëŸ°ì˜ `model_selection` ì˜ `train_test_split` í•¨ìˆ˜ë¥¼ í™œìš©
- `train_test_split()` í•¨ìˆ˜ì˜ íŒŒë¼ë¯¸í„°
  - test_size(ê¸°ë³¸ê°’ : 0.25)
    - ì „ì²´ ë°ì´í„°ì…‹ì—ì„œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ í¬ê¸°ë¥¼ ì–¼ë§ˆë¡œ ìƒ˜í”Œë§í•  ê²ƒì¸ì§€ ê²°ì •
  - train_size : 
    - ì „ì²´ ë°ì´í„°ì…‹ì—ì„œ í•™ìŠµ ë°ì´í„°ì…‹ í¬ê¸°ë¥¼ ì–¼ë§ˆë¡œ ìƒ˜í”Œë§í•  ê²ƒì¸ì§€ ê²°ì •. 
    - test_sizeë¥¼ ì£¼ë¡œ í™œìš©í•˜ê¸° ë•Œë¬¸ì—, ì˜ ì“°ì´ì§€ëŠ” ì•ŠìŒ
  - shuffle(ê¸°ë³¸ê°’: True)
    - ë°ì´í„°ë¥¼ ë¶„ë¦¬í•˜ê¸° ì „ì— ë°ì´í„°ë¥¼ ì„ì„ì§€ ê²°ì •í•˜ëŠ” íŒŒë¼ë¯¸í„°
    - ë°ì´í„°ë¥¼ ë¶„ì‚°ì‹œì¼œ ë³´ë‹¤ íš¨ìœ¨ì ì¸ í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„¸íŠ¸ë¥¼ ë§Œë“œëŠ”ë° ì‚¬ìš©
  - random_state : ë‚œìˆ˜ê°’ì„ ì§€ì •í•˜ë©´ ì—¬ëŸ¬ ë²ˆ ë‹¤ì‹œ ìˆ˜í–‰í•´ë„ ë™ì¼í•œ ê²°ê³¼ê°€ ë‚˜ì˜¤ê²Œ í•´ì¤ë‹ˆë‹¤.
- train_test_splitì˜ ë°˜í™˜ ê°’ì€ íŠœí”Œí˜•íƒœë¡œ ì•„ë˜ì˜ ìˆœì„œ
  - (1) í•™ìŠµ ë°ì´í„°ì…‹
  - (2) í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹
  - (3) í•™ìŠµ ë°ì´í„°ì…‹ì˜ ë ˆì´ë¸”
  - (4) í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹

```python
y_titanic_df = df['Survived']
X_titanic_df = df.drop('Survived', axis=1, inplace=False)
X_titanic_df = transform_features(X_titanic_df)

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, test_size=0.2, random_state=11)

X_titanic_df
```

<br>

## ëª¨ë¸ í•™ìŠµ
- DecisionTreeClassifier
- RandomForestClassifier
- LogisticRegression

```python
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# ëª¨ë¸ ì •ì˜
models = {
    'DecisionTree': DecisionTreeClassifier(random_state=44),
    'RandomForest': RandomForestClassifier(random_state=44),
    'LogisticRegression' : LogisticRegression(solver='liblinear')
}
```


<br>

## í‰ê°€
```python
def evaluate_models(models, X_train, X_test, y_train, y_test):
    results = {}
    for name, model in models.items():
        model.fit(X_train, y_train)
        pred = model.predict(X_test)
        acc = accuracy_score(y_test, pred)
        results[name] = acc
        print(f'{name} ì •í™•ë„: {acc:.4f}')
        print("Confusion Matrix:\n", confusion_matrix(y_test, pred))
        print("Classification Report:\n", classification_report(y_test, pred))
    return results

# ëª¨ë¸ í‰ê°€
results = evaluate_models(models, X_train, X_test, y_train, y_test)
```

- ê²°ê³¼

    ``` 
    DecisionTree ì •í™•ë„: 0.8045
    Confusion Matrix:
    [[101  17]
    [ 18  43]]
    Classification Report:
                precision    recall  f1-score   support

            0       0.85      0.86      0.85       118
            1       0.72      0.70      0.71        61

        accuracy                           0.80       179
    macro avg       0.78      0.78      0.78       179
    weighted avg       0.80      0.80      0.80       179

    RandomForest ì •í™•ë„: 0.8436
    Confusion Matrix:
    [[106  12]
    [ 16  45]]
    Classification Report:
                precision    recall  f1-score   support

            0       0.87      0.90      0.88       118
            1       0.79      0.74      0.76        61

        accuracy                           0.84       179
    macro avg       0.83      0.82      0.82       179
    weighted avg       0.84      0.84      0.84       179

    LogisticRegression ì •í™•ë„: 0.8659
    Confusion Matrix:
    [[108  10]
    [ 14  47]]
    Classification Report:
                precision    recall  f1-score   support

            0       0.89      0.92      0.90       118
            1       0.82      0.77      0.80        61

        accuracy                           0.87       179
    macro avg       0.85      0.84      0.85       179
    weighted avg       0.86      0.87      0.86       179
    ```

<br>

### ê²°ê³¼ ì‹œê°í™”
```python
import matplotlib.pyplot as plt

plt.bar(results.keys(), results.values())
plt.title('Model Accuracy Comparison')
plt.ylabel('Accuracy')
plt.show()
```

- ê²°ê³¼

![image](https://github.com/user-attachments/assets/8253fd63-4649-4280-96a9-fef73d19c7b6)


<br>
<br>


# ğŸ’¡Today I Thought

## ì˜¤ëŠ˜ì˜ ì²´í¬ë¦¬ìŠ¤íŠ¸
- [x]  ì•Œê³ ë¦¬ì¦˜ ì½”ë“œì¹´íƒ€ 81-90
- [x]  SQL ì½”íŠ¸ì¹´íƒ€ 59-60
- [x]  ë°±ì¤€ ì½”ë”©í…ŒìŠ¤íŠ¸ 1ë¬¸ì œ
- [x]  ì¥ê³  ê°•ì˜ 17ê°•ê¹Œì§€
- [x]  TIL ì‘ì„±

## íšŒê³ 
&nbsp; ì¥ê³ ê°•ì˜ ë“¤ìœ¼ë©´ì„œ ì •ì‹ ì—†ì§€ë§Œ, í˜¹ì‹œ ë‚˜ì¤‘ì— ì–´ë–¤ê±¸ í•˜ê²Œ ë ì§€ ëª¨ë¥´ë‹ˆê¹Œ ë¨¸ì‹ ëŸ¬ë‹ ê³µë¶€ë„ ê¾¸ì¤€íˆ í•˜ë ¤ê³ .. í•™ìŠµë°˜ì—ì„œ í–ˆë˜ ë‚´ìš©ì„ ì •ë¦¬í•´ë´¤ë‹¤. ë°˜ë„ ëª»í•˜ê¸´ í–ˆì§€ë§Œ..ğŸ¤” ê³µë¶€í•˜ë ¤ê³  ë¹Œë ¤ì˜¨ ì±…ë„ í´ë´ì•¼í•˜ëŠ”ë° ì§€ê¸ˆì€ ì¥ê³  ì«“ì•„ê°€ê¸°ë„ ë„ˆë¬´ ë²„ê²ë‹¤ğŸ˜° í•˜ë£¨ê°€ 40ì‹œê°„ì´ë©´ ì¢‹ê² ì–´..