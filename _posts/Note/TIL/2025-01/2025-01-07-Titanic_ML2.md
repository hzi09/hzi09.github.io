---
title:  "[TIL] 내일배움캠프 42일차_[ML] Titanic 데이터를 사용한 머신러닝(2)" 

categories: 
    - TIL
tags: 
    - TIL
    - 내일배움캠프
    - 머신러닝


toc: True
toc_sticky: True
---

![TIL](/assets/images/TIL2.png){: .align-center style="width:35%;"}

# 👀Today I Learn
## 모델 학습
- K-Fold 교차검증
  - 집합을 체계적으로 바꿔가면서 모든 데이터에 대해 모형의 성과를 측정하는 검증 방식

    ![image](https://github.com/user-attachments/assets/fd8a27d6-d83b-4f24-bd48-ce517d484c0c){: width="35%" height="35%"}

- K-Fold 교차검증
    ```python
    # for 문
    from sklearn.model_selection import KFold
    import numpy as np

    def exec_kfold(clf, folds=5):
        kfold = KFold(n_splits=folds)
        scores = []
        for iter_count, (train_index, test_index) in enumerate(kfold.split(X_titanic_df)):
            X_train, X_test = X_titanic_df.values[train_index], X_titanic_df.values[test_index]
            y_train, y_test = y_titanic_df.values[train_index], y_titanic_df.values[test_index]

            clf.fit(X_train, y_train)
            predictions = clf.predict(X_test)

            accuracy = accuracy_score(y_test, predictions)
            scores.append(accuracy)
            print(f'교차 검증 {iter_count} 정확도: {accuracy:.4f}')

        mean_score = np.mean(scores)
        print(f'평균 정확도: {mean_score:.4f}')

    exec_kfold(DecisionTreeClassifier(random_state=11))
    ```

- 결과
    ```
    교차 검증 0 정확도: 0.7542
    교차 검증 1 정확도: 0.7809
    교차 검증 2 정확도: 0.7865
    교차 검증 3 정확도: 0.7697
    교차 검증 4 정확도: 0.8202
    평균 정확도: 0.7823
    ```

<br>

## cross_val_score()
- 교차검증을 위한 함수
  - 주어진 데이터셋을 'k'개의 fold로 분할하고, 각 fold에서 모델을 학습시키고 검증하는 과정을 'k'번 반복하여 모델의 성능을 평가
  - 장점
    - 모델의 성능을 더욱 정확하게 예측 가능
    - 과적합을 방지하고, 모델이 일반화 될 수 있도록함
    - 모델의 신뢰도를 높힐 수 있음
  - 단점
    - 계산 비용이 매우 높을 수 있음

- `cross_val_score()`
    ```python
    from sklearn.model_selection import cross_val_score

    scores = cross_val_score(DecisionTreeClassifier(random_state=44), X_titanic_df, y_titanic_df, cv=5)

    for iter_count, accuracy in enumerate(scores):
        print(f'교차 검증: {iter_count}, 정확도: {accuracy}')
    print(f'평균 정확도 >>>> {np.mean(scores):.4f}')
    ```

- 결과
    ```
    교차 검증: 0, 정확도: 0.7653631284916201
    교차 검증: 1, 정확도: 0.7752808988764045
    교차 검증: 2, 정확도: 0.797752808988764
    교차 검증: 3, 정확도: 0.7808988764044944
    교차 검증: 4, 정확도: 0.8258426966292135
    평균 정확도 >>>> 0.7890
    ```

<br>

## 하이퍼파라미터 튜닝
### 1. 조합 정의
- depth : 너무 깊으면 과적합이 될 가능성이 높아짐
- split : 작으면 작을수록 트리가 복잡해짐
- leaf : 리프 노드가 최소한의 데이터를 포함하도록 설정

```python
# 라이브러리 가져오기
from sklearn.model_selection import GridSearchCV
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

parameters = {'max_depth': [2, 3, 5, 10],
            'min_samples_split': [2, 3, 5],
            'min_samples_leaf': [1, 5, 8]}
```
- 이 경우 조합의 개수는 4 × 3 × 3 = 36

### 2. 교차검증
```python
grid_dclf = GridSearchCV(
    estimator=DecisionTreeClassifier(random_state=44),
    param_grid=parameters,
    scoring='accuracy',
    cv=5
)

grid_dclf.fit(X_titanic_df, y_titanic_df)
```

### 3. 최적의 조합 선택
```python
print(f'최적의 파라미터 >>>> {grid_dclf.best_params_}')
print(f'최고 교차 검증 정확도 >>>> {grid_dclf.best_score_}')
```
- 결과
    ```
    최적의 파라미터 >>>> {'max_depth': 10, 'min_samples_leaf': 8, 'min_samples_split': 2}
    최고 교차 검증 정확도 >>>> 0.8159751428033394
    ```

### 4. 최적의 모델 반환
```python
st_model = grid_dclf.best_estimator_
best_model
pred = best_model.predict(X_titanic_df)

print(f'GridSearchCV 최적의 값 >>>> {accuracy_score(y_titanic_df, pred)}')
```

- 결과
    ```
    GridSearchCV 최적의 값 >>>> 0.8720538720538721
    ```

<br>
<br>


# 💡Today I Thought

## 오늘의 체크리스트
- [x]  알고리즘 코드카타 91-100
- [x]  SQL 코트카타 61
- [x]  백준 코딩테스트 1문제
- [x]  장고 강의 18강까지
- [x]  스탠다드반 과제
- [x]  TIL 작성

## 회고
&nbsp; 오늘은 목표 완료! 원래는 20강까지 들으려고 했는데, 생각보다 18강이 오래 걸렸다.(117분 강의는 힘들다.. 끝나지 않아..) 머신러닝 정리도 끝! 조금 자세한 내용은 따로 공부해서 포스팅으로 남겨둬야지! 이제 과제발제가 얼마 안남았으니까 내일은 장고 기초 강의 꼭 끝내고 심화 시작해야겠다.😰