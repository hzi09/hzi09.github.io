---
title:  "[TIL] 내일배움캠프 62일차_[LLM] Llama-2-7b 사용해보기" 

categories: 
    - TIL
tags: 
    - TIL
    - 내일배움캠프
    - LLM


toc: True
toc_sticky: True
---

![TIL](/assets/images/TIL2.png){: .align-center style="width:35%;"}

# 👀Today I Learn
## Llama
- LLaMA(Large Language Model Meta AI, 대형 언어 모델 메타 AI)는 Meta AI가 2023년 2월에 출시한 대규모 언어 모델(LLM)
- On-premise(자체기반)에서 구동
  - On-premise : 클라우드가 아닌 자체적으로 가지고 있는 서버를 의미

### Llama-2-7-b사용해보기
1. 폴더 및 가상환경 생성

    ```bash
    python -m venv llma_env
    ```

2. 라이브러리 설치

    ```bash
    pip install tranformers huggingface_hub torch
    ```

3. Hugging Face 가입하기

   - 링크 :[Hugging Face](https://huggingface.co/settings/tokens/new?tokenType=fineGrained)

4. Token 발급하기
   - llama2-7b 검색

       ![Image](https://github.com/user-attachments/assets/63fc7178-327e-49ae-8ed8-9f1e61f72796)

   - 해당 페이지의 `Expand to review and access` 누르기(나는.. 이미 해서 안보여서 다른 모델에서 캡쳐함)

       ![Image](https://github.com/user-attachments/assets/831ee92f-2b59-4d49-886c-27ba01bcd0fd)

   - 누르면 하단에 정보 입력이 나옴! 입력!

       ![Image](https://github.com/user-attachments/assets/05c302a7-6184-4ec3-80e9-15b275c30625)

   - 승인되면 메일이 옴. 한 5~10분정도 소요되는 것 같음

       ![Image](https://github.com/user-attachments/assets/4c877e39-ef64-465d-a0fb-dba1de08223d)

   - 우측 상단의 프로필을 눌러서 setting -> Access Tokens에서 Create new Token 선택

       ![Image](https://github.com/user-attachments/assets/16c6ef13-38ee-4613-8711-88329ae8ddfa)

   - Token 생성
       - token name 작성
       - Repositories는 다 선택
       - Repositories permissions에서 검색 : Llama-2-7b

       ![Image](https://github.com/user-attachments/assets/77cd5f83-ef43-437c-ada5-ca5f2369217e)

   - 맨 아래로 내려서 Create token 하면 완성
     - ⚠️ 주의! : token은 한번만 볼 수 있으니까 미리 복사해서 저장해두자ㅠㅠ

5. VSCode에서 로그인하기

    ```bash
    huggingface-cli login
    ```
   - 토큰은 안보이게 입력되므로 우클릭 한번만 하자!

       ![Image](https://github.com/user-attachments/assets/aa95e025-4fec-45a9-a70d-a79ffa48ad8d)

6. main/main.py 생성
    
    ```python
    from transformers import AutoTokenizer, AutoModelForCausalLM

    tokenizer = AutoTokenizer.from_pretrained("meta-llama/Llama-2-7b-chat-hf")
    model = AutoModelForCausalLM.from_pretrained("meta-llama/Llama-2-7b-chat-hf")

    # 입력 메시지
    input_text = "How is korea?"
    inputs = tokenizer(input_text, return_tensors="pt")

    # 텍스트 생성
    outputs = model.generate(**inputs, max_length=50)
    print(tokenizer.decode(outputs[0], skip_special_tokens=True))
    ```

    - 실행

        ```bash
        python main.py
        ```

        ![Image](https://github.com/user-attachments/assets/6be55ed2-3938-4581-810a-ba9286721542)

        - 아주.. 오래된.. 시간후에 나온 결과..(한 10분정도 소요됨)

            ![Image](https://github.com/user-attachments/assets/53492316-8d15-4bde-9436-124b504ef45d)


<br>
<br>

# 💡Today I Thought

## 오늘의 체크리스트
- [x]  알고리즘 코드카타 271-275
- [x]  SQL 코드카타 92-93
- [x]  Docker 1강 듣기
- [x]  LLM 특강 듣고 내용 정리
- [x]  자가 검진 테스트
- [x]  TIL 작성

## 회고
&nbsp; 오늘 공부하기 싫었지만,, 꾹꾹 참고,, 적당히 공부를 해냈다. 내일부터는 본격적으로 정처기 문제 풀이 할 예정이라 오늘 쉴수가 없었다.😭😭 그래도 생각보다 많이 해서 뿌듯하다ㅎㅎ