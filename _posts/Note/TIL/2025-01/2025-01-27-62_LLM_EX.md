---
title:  "[TIL] ë‚´ì¼ë°°ì›€ìº í”„ 62ì¼ì°¨_[LLM] Llama-2-7b ì‚¬ìš©í•´ë³´ê¸°" 

categories: 
    - TIL
tags: 
    - TIL
    - ë‚´ì¼ë°°ì›€ìº í”„
    - LLM


toc: True
toc_sticky: True
---

![TIL](/assets/images/TIL2.png){: .align-center style="width:35%;"}

# ğŸ‘€Today I Learn
## Llama
- LLaMA(Large Language Model Meta AI, ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ ë©”íƒ€ AI)ëŠ” Meta AIê°€ 2023ë…„ 2ì›”ì— ì¶œì‹œí•œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)
- On-premise(ìì²´ê¸°ë°˜)ì—ì„œ êµ¬ë™
  - On-premise : í´ë¼ìš°ë“œê°€ ì•„ë‹Œ ìì²´ì ìœ¼ë¡œ ê°€ì§€ê³  ìˆëŠ” ì„œë²„ë¥¼ ì˜ë¯¸

### Llama-2-7-bì‚¬ìš©í•´ë³´ê¸°
1. í´ë” ë° ê°€ìƒí™˜ê²½ ìƒì„±

    ```bash
    python -m venv llma_env
    ```

2. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜

    ```bash
    pip install tranformers huggingface_hub torch
    ```

3. Hugging Face ê°€ì…í•˜ê¸°

   - ë§í¬ :[Hugging Face](https://huggingface.co/settings/tokens/new?tokenType=fineGrained)

4. Token ë°œê¸‰í•˜ê¸°
   - llama2-7b ê²€ìƒ‰

       ![Image](https://github.com/user-attachments/assets/63fc7178-327e-49ae-8ed8-9f1e61f72796)

   - í•´ë‹¹ í˜ì´ì§€ì˜ `Expand to review and access` ëˆ„ë¥´ê¸°(ë‚˜ëŠ”.. ì´ë¯¸ í•´ì„œ ì•ˆë³´ì—¬ì„œ ë‹¤ë¥¸ ëª¨ë¸ì—ì„œ ìº¡ì³í•¨)

       ![Image](https://github.com/user-attachments/assets/831ee92f-2b59-4d49-886c-27ba01bcd0fd)

   - ëˆ„ë¥´ë©´ í•˜ë‹¨ì— ì •ë³´ ì…ë ¥ì´ ë‚˜ì˜´! ì…ë ¥!

       ![Image](https://github.com/user-attachments/assets/05c302a7-6184-4ec3-80e9-15b275c30625)

   - ìŠ¹ì¸ë˜ë©´ ë©”ì¼ì´ ì˜´. í•œ 5~10ë¶„ì •ë„ ì†Œìš”ë˜ëŠ” ê²ƒ ê°™ìŒ

       ![Image](https://github.com/user-attachments/assets/4c877e39-ef64-465d-a0fb-dba1de08223d)

   - ìš°ì¸¡ ìƒë‹¨ì˜ í”„ë¡œí•„ì„ ëˆŒëŸ¬ì„œ setting -> Access Tokensì—ì„œ Create new Token ì„ íƒ

       ![Image](https://github.com/user-attachments/assets/16c6ef13-38ee-4613-8711-88329ae8ddfa)

   - Token ìƒì„±
       - token name ì‘ì„±
       - RepositoriesëŠ” ë‹¤ ì„ íƒ
       - Repositories permissionsì—ì„œ ê²€ìƒ‰ : Llama-2-7b

       ![Image](https://github.com/user-attachments/assets/77cd5f83-ef43-437c-ada5-ca5f2369217e)

   - ë§¨ ì•„ë˜ë¡œ ë‚´ë ¤ì„œ Create token í•˜ë©´ ì™„ì„±
     - âš ï¸ ì£¼ì˜! : tokenì€ í•œë²ˆë§Œ ë³¼ ìˆ˜ ìˆìœ¼ë‹ˆê¹Œ ë¯¸ë¦¬ ë³µì‚¬í•´ì„œ ì €ì¥í•´ë‘ìã… ã… 

5. VSCodeì—ì„œ ë¡œê·¸ì¸í•˜ê¸°

    ```bash
    huggingface-cli login
    ```
   - í† í°ì€ ì•ˆë³´ì´ê²Œ ì…ë ¥ë˜ë¯€ë¡œ ìš°í´ë¦­ í•œë²ˆë§Œ í•˜ì!

       ![Image](https://github.com/user-attachments/assets/aa95e025-4fec-45a9-a70d-a79ffa48ad8d)

6. main/main.py ìƒì„±
    
    ```python
    from transformers import AutoTokenizer, AutoModelForCausalLM

    tokenizer = AutoTokenizer.from_pretrained("meta-llama/Llama-2-7b-chat-hf")
    model = AutoModelForCausalLM.from_pretrained("meta-llama/Llama-2-7b-chat-hf")

    # ì…ë ¥ ë©”ì‹œì§€
    input_text = "How is korea?"
    inputs = tokenizer(input_text, return_tensors="pt")

    # í…ìŠ¤íŠ¸ ìƒì„±
    outputs = model.generate(**inputs, max_length=50)
    print(tokenizer.decode(outputs[0], skip_special_tokens=True))
    ```

    - ì‹¤í–‰

        ```bash
        python main.py
        ```

        ![Image](https://github.com/user-attachments/assets/6be55ed2-3938-4581-810a-ba9286721542)

        - ì•„ì£¼.. ì˜¤ë˜ëœ.. ì‹œê°„í›„ì— ë‚˜ì˜¨ ê²°ê³¼..(í•œ 10ë¶„ì •ë„ ì†Œìš”ë¨)

            ![Image](https://github.com/user-attachments/assets/53492316-8d15-4bde-9436-124b504ef45d)


<br>
<br>

# ğŸ’¡Today I Thought

## ì˜¤ëŠ˜ì˜ ì²´í¬ë¦¬ìŠ¤íŠ¸
- [x]  ì•Œê³ ë¦¬ì¦˜ ì½”ë“œì¹´íƒ€ 271-275
- [x]  SQL ì½”ë“œì¹´íƒ€ 92-93
- [x]  Docker 1ê°• ë“£ê¸°
- [x]  LLM íŠ¹ê°• ë“£ê³  ë‚´ìš© ì •ë¦¬
- [x]  ìê°€ ê²€ì§„ í…ŒìŠ¤íŠ¸
- [x]  TIL ì‘ì„±

## íšŒê³ 
&nbsp; ì˜¤ëŠ˜ ê³µë¶€í•˜ê¸° ì‹«ì—ˆì§€ë§Œ,, ê¾¹ê¾¹ ì°¸ê³ ,, ì ë‹¹íˆ ê³µë¶€ë¥¼ í•´ëƒˆë‹¤. ë‚´ì¼ë¶€í„°ëŠ” ë³¸ê²©ì ìœ¼ë¡œ ì •ì²˜ê¸° ë¬¸ì œ í’€ì´ í•  ì˜ˆì •ì´ë¼ ì˜¤ëŠ˜ ì‰´ìˆ˜ê°€ ì—†ì—ˆë‹¤.ğŸ˜­ğŸ˜­ ê·¸ë˜ë„ ìƒê°ë³´ë‹¤ ë§ì´ í•´ì„œ ë¿Œë“¯í•˜ë‹¤ã…ã…