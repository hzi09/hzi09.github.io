---
title:  "[TIL] 내일배움캠프 73일차_[LLM] LLM 톺아보기" 

categories: 
    - TIL
tags: 
    - TIL
    - 내일배움캠프
    - LLM


toc: True
toc_sticky: True
---

![TIL](/assets/images/TIL2.png){: .align-center style="width:35%;"}

# 👀Today I Learn
## 1. LLM 톺아보기
### LLM(Large Language Model)
- LLM(Large Language Model, 대규모 언어 모델) 은 대량의 텍스트 데이터를 학습하여 자연어를 이해하고 생성하는 모델
- 기반 기술: 트랜스포머(Transformer) 아키텍처
- 활용 예시: GPT-4, BERT, Claude, Gemini 등

### MLP(Multilayer Perceptron)

  ![Image](https://github.com/user-attachments/assets/c65f3016-1e2a-4959-ae85-01c0d3406074){: .align-center}

- 기본적인 신경망(NN) 구조로, 입력층 → 은닉층 → 출력층의 형태를 가짐
- 퍼셉트론(Perceptron)은 뉴런의 개념을 차용하여 데이터를 이진분류(Binary Classification) 가능하게 설계됨
- XOR 문제 해결을 위해 여러 개의 퍼셉트론을 조합한 MLP 등장
- 더 깊은 네트워크 구조(Deep Neural Network, DNN)를 통해 복잡한 패턴을 학습 가능

<br>

## 2. 트랜스포머(Transformer)
### 기존 문제점
- MLP는 고정된 길이의 입력을 처리하는 데 적합하지만, 자연어와 같은 가변 길이 데이터에서는 한계가 존재
- RNN (Recurrent Neural Network)은 시퀀스 데이터를 처리할 수 있도록 개선되었으나, 장기 의존성 문제, 기울기 소실 문제, 속도 문제 등 단점이 존재
- 이를 보완하기 위해 LSTM(Long Short-Term Memory), GRU(Gated Recurrent Unit) 등이 등장했으나, 여전히 학습 속도가 느림

  ![Image](https://github.com/user-attachments/assets/23a3819d-477b-4f45-ae34-e210d3914539)

### 트랜스포머의 등장
- 순차적인 처리 없이 전체 문장을 한 번에 처리할 수 있도록 설계됨
- 핵심 기술: 어텐션(Attention) 메커니즘
  - 문장에서 단어 간의 관계를 파악하여 가중치를 부여하는 방식
  - 모든 단어를 벡터로 변환한 후, 서로 얼마나 관련이 있는지를 수치화(어텐션 스코어 계산)

### 트랜스포머의 장점
- 병렬 연산 가능 → RNN 대비 학습 속도가 빠름
- GPU 병렬 처리 최적화 → 대규모 데이터 학습 가능
- 긴 문맥 유지 가능 → 자연어 처리 성능이 획기적으로 향상됨
- 결과: 트랜스포머 기반의 GPT-3, GPT-4, BERT 등의 LLM이 등장하며 자연어 처리 기술이 비약적으로 발전

<br>

## 3. LLM 조망하기
### LLM의 본질
- LLM을 단순한 데이터베이스로 오해하면 안 됨
- 단순한 검색 기능이 아니라, **추론**과 **생성** 능력을 포함하는 모델
- OpenAI의 샘 알트먼(Sam Altman)은 *"ChatGPT는 데이터베이스가 아니라 추론 엔진"*이라고 설명

### 프롬프트 엔지니어링
- 프롬프트 엔지니어링은 모델의 출력을 최적화하기 위한 기법
- 대표적인 기법
  - Few-shot Prompting
    - 일반적인 프롬프트(Zero-shot Prompting)
      - 모델에게 추가적인 예시를 제공하지 않고, 바로 질문을 던지는 방식

        ![Image](https://github.com/user-attachments/assets/a99e5353-57d8-40f4-b00b-9655e0de7235)

    - Few-shot Prompting
      - 원하는 응답의 예시를 제시하여 더 정교한 답변을 유도
        
        ![Image](https://github.com/user-attachments/assets/49246947-423f-46ab-a422-a7def7d1f4cf)

  - Role Prompting(역할 프롬프트)
    - 모델 자체가 자신이 누구인지를 인식하고 그에 맞는 답변 스타일을 유지하도록 할 수 있음
        
        ![Image](https://github.com/user-attachments/assets/a5f2725f-f0b6-42fc-9246-30dd8730baab)

  - CoT (Chain-of-ThoughtPrompting)
    - 논리적 사고 과정을 강조하여 답변을 생성

        ![Image](https://github.com/user-attachments/assets/026942db-c322-4cac-9341-6a29c5cd01a0)

<br>

## 4. MMLU : 모델 성능 평가
### MMLU란?
- MMLU (Massive Multitask Language Understanding) 은 LLM 성능을 평가하는 벤치마크
- 제로샷 및 퓨샷 설정에서만 모델을 테스트
- 모델이 사전 훈련 중에 학습한 지식만을 평가

### 최신 LLM 성능
- 인간 전문가의 MMLU 정확도: 89.9%
- 최신 LLM(GPT-4, Gemini, Claude 3.5 등)의 정확도: 90% 이상
- 💡결론: LLM이 인간 전문가 수준에 도달했음을 시사

<br>

## 5. LLM을 대하는 우리의 자세
### "Large"의 의미
- 트랜스포머 덕분에 스케일이 기하급수적으로 증가
- 파라미터 수: 몇 천억 단위
- 훈련 데이터 크기: 수백 기가바이트

### 직접 학습할 수 있을까?
- LLM을 학습하려면 엄청난 GPU 메모리(VRAM) 가 필요
- 현실적으로 대기업이 제공하는 사전 학습된 모델을 활용하는 것이 최선
- 💡따라서 우리는 "모델 개발"이 아니라 "모델 활용"에 집중해야 함.

<br>

## 6. LLM 활용 전략
### 프롬프팅 (Prompting)
- 추가적인 훈련 없이 텍스트 입력만으로 모델을 조정
- 빠르고 비용이 적지만, 기존 학습된 데이터에 한정됨
- 맥락을 추가할 수 있지만 한계 존재

### RAG (Retrieval-Augmented Generation)
- LLM이 외부 데이터를 검색하여 최신 정보를 활용하도록 하는 기법
- 검색 시스템과 결합하여 실시간 정보 반영 가능
- 단점: Garbage In, Garbage Out (잘못된 데이터가 들어가면 잘못된 답변이 나옴)

### 파인 튜닝 (Fine-Tuning)
- 특정 도메인에 맞춰 추가 훈련
- 모델을 다시 학습시켜 맞춤형 AI 제작 가능
- 단점: 훈련 비용이 많이 들고, 시간이 오래 걸림

> 정답은 없음! 서비스에 따라 가장 적합한 방법을 선택해야 함.
> - 빠른 조정 → 프롬프팅
> - 최신 정보 반영 → RAG
> - 특정 도메인 특화 → 파인 튜닝
> - 이 세 가지를 조합하여 활용하는 것도 가능!
>   - 예: 모델을 파인 튜닝한 후, RAG를 적용하고, 프롬프팅을 최적화하는 방식


<br>
<br>

# 💡Today I Thought

## 오늘의 체크리스트
- [x]  알고리즘 코드카타 319
- [x]  SQL 코드카타 107
- [x]  AI 모델 활용 5-1~5-3 강의 듣기
- [x]  스탠다드반 수업 복습
- [x]  TIL 작성
- [x]  WIL 작성

## 회고
&nbsp;벌써 금요일🫠 어제 저녁부터 컨디션이 안좋아서 결석해야하나 고민했는데 그래도.. 어떻게든 할 수 있을 것 같아서 일단 앉았다.(온라인이라서 가능했다 진짜😢) 오늘 LLM 강의에서 스탠다드반에서 다뤘던 내용들이 한번씩 보여서 너무 반가웠다. 근데 복습을 확실하게 안했는지 대답은 잘 못했음😫 제발 공부 좀 꼼꼼하게 하자ㅠㅠ