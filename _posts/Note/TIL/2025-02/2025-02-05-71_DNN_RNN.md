---
title:  "[TIL] 내일배움캠프 71일차_[DL] DNN과 RNN" 

categories: 
    - TIL
tags: 
    - TIL
    - 내일배움캠프
    - 딥러닝
    - DNN
    - RNN


toc: True
toc_sticky: True
---

![TIL](/assets/images/TIL2.png){: .align-center style="width:35%;"}

# 👀Today I Learn
## 개요
- 딥러닝(Deep Learning)에서 신경망은 다양한 구조를 가지며, 그중 DNN(Deep Neural Network)과 RNN(Recurrent Neural Network)은 대표적인 모델
- 이 두 가지 모델은 특정한 문제를 해결하는 데 최적화되어 있으며, 서로 다른 특징을 가지고 있음
  - DNN은 일반적인 패턴을 학습하는 데 강함
  - RNN은 시간에 따라 변하는 데이터를 다루는 데 특화된 모델

<br>

## DNN(Deep Neural Network)

![Image](https://github.com/user-attachments/assets/2d9ae605-c04e-481d-9c57-7e8e64cf899e){: .align-center}

- DNN은 여러 개의 층으로 이루어진 신경망
- 층이 많아질수록 더 깊이 있는 패턴을 학습할 수 있기 때문에 '딥(Deep)' 신경망이라고 불림
  - 입력층(Input Layer): 데이터가 처음 들어오는 부분
  - 은닉층(Hidden Layer): 데이터를 가공하여 의미 있는 정보를 추출하는 부분
  - 출력층(Output Layer): 최종 결과를 도출하는 부분
- DNN은 각 층을 통과할 때마다 데이터가 조금씩 변형되어 더 정교한 특징을 학습함


### 구조 및 특징
- 다층 구조: 여러 층이 연결되어 깊이 있는 학습이 가능
- 순전파(Forward Propagation): 입력 데이터를 거쳐 최종 결과를 출력하는 과정
- 역전파(Backpropagation): 모델이 틀린 답을 냈을 때, 가중치를 조정하여 학습하는 과정
- 활성화 함수(Activation Function): 비선형성을 추가하여 더 복잡한 패턴을 학습할 수 있도록 함 (ReLU, Sigmoid, Tanh 등)
- 정형 데이터 처리: 예를 들어, 사진 속의 고양이와 개를 구별하는 데 유용함

### 활용 사례
- 이미지 분류: 고양이와 개를 구별하는 모델
- 음성 인식: 녹음된 목소리를 텍스트로 변환하는 기술
- 추천 시스템: 유튜브, 넷플릭스 등에서 개인 맞춤형 추천 제공
- 의료 진단: MRI 영상을 분석하여 질병을 예측

<br>

## RNN (Recurrent Neural Network)

![Image](https://github.com/user-attachments/assets/8723650a-d708-40d1-b44b-aaff924afc03){: .align-center}

- RNN은 시간에 따라 변화하는 데이터를 다루는 데 특화된 신경망
- 일반적인 DNN은 현재 입력만 보고 예측하지만, RNN은 과거 정보를 기억하여 더 정확한 예측을 할 수 있음

### 구조 및 특징
- 반복적인 구조: 이전의 정보를 다음 단계로 전달하여 시계열 데이터를 학습할 수 있음
- 메모리 기능: 과거 데이터를 저장하고 다음 계산에 반영함
- 장기 의존성 문제: 시간이 지나면서 과거 정보가 흐려지는 문제 발생 (Gradient Vanishing)
- LSTM, GRU 발전: 과거 정보를 더 잘 기억하도록 개선된 구조 등장

### 활용 사례
- 번역 모델: 영어 문장을 한국어로 번역하는 모델 (Google Translate 등)
- 음성 인식: 실시간 대화에서 음성을 문자로 변환하는 기술
- 주가 예측: 과거 주식 데이터를 바탕으로 미래 주가 변동 예측
- 챗봇: 대화의 흐름을 기억하고 자연스럽게 응답하는 AI

<br>

## DNN vs RNN

| 특징 | DNN (Deep Neural Network) | RNN (Recurrent Neural Network) |
| :---: | --- | --- |
| 구조 | 여러 층으로 구성된 일반 신경망 | 반복적으로 정보를 전달하는 순환 신경망 |
| 데이터 처리 방식 | 독립적인 입력 데이터 처리 | 시간 흐름에 따라 연속적인 데이터 처리 |
| 기억 메커니즘 | 없음 | 과거 정보를 저장하고 활용 |
| 주 활용 분야 | 이미지, 음성, 정형 데이터 분석 | 자연어 처리, 시계열 데이터 |
| 문제점 | 고정된 크기의 데이터만 다룰 수 있음 | 과거 정보를 오래 기억하기 어려움 (Gradient Vanishing) |
| 해결책 | CNN, 트랜스포머 모델 결합 | LSTM, GRU로 개선 |

## 코드 예제
### DNN 구현 
- DNN은 정적인 데이터를 학습하는 데 유용
- 예를 들어, 고양이와 개를 구별하는 이미지 분류 모델을 만들 때 DNN을 사용할 수 있음
- TensorFlow/Keras를 사용한 코드
  
    ```python
    import tensorflow as tf
    from tensorflow import keras
    from tensorflow.keras import layers

    # 간단한 DNN 모델 정의
    # Sequential() : 층을 순차적으로 쌓는 모델
    model = keras.Sequential([
        # 첫 번째 은닉층, 입력 데이터 크기 지정
        # Dense(64, activation='relu') : 64개의 뉴런을 가진 은닉층을 만들고 ReLU 활성화 함수 적용
        # input_shape=(input_dim,) : 입력 데이터의 차원을 설정
        layers.Dense(64, activation='relu', input_shape=(input_dim,)),  
        # 두 번째 은닉층
        layers.Dense(64, activation='relu'),  
        # 출력층, 다중 클래스 분류를 위해 softmax 사용
        layers.Dense(output_dim, activation='softmax')  
    ])

    # 모델 컴파일 - 옵티마이저, 손실 함수, 평가 지표 설정
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    ```

### RNN 구현 
- RNN은 순차적인 데이터를 다룰 때 유용 
- 예를 들어, 주식 가격 예측, 자연어 처리 등과 같은 시간의 흐름이 중요한 데이터를 분석할 때 사용됨
- TensorFlow/Keras

    ```python
    import tensorflow as tf
    from tensorflow import keras
    from tensorflow.keras import layers

    # 간단한 RNN 모델 정의
    model = keras.Sequential([
        # RNN 층, 입력 데이터 크기 지정
        # input_shape=(timesteps, input_dim) : 시계열 데이터를 입력으로 받음
        layers.SimpleRNN(64, activation='relu', input_shape=(timesteps, input_dim)),
        # 출력층, 다중 클래스 분류를 위해 softmax 사용
        layers.Dense(output_dim, activation='softmax')
    ])

    # 모델 컴파일 - 옵티마이저, 손실 함수, 평가 지표 설정
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    ```

<br>
<br>


# 💡Today I Thought

## 오늘의 체크리스트
- [x]  알고리즘 코드카타 316
- [x]  SQL 코드카타 105
- [x]  AI 모델 활용 3주차 강의 듣기
- [x]  딥러닝 복습
- [x]  TIL 작성

## 회고
&nbsp; 오늘 코드카타는 1시간이 훌쩍 넘어버려서 조금만 했다. 이젠 진짜 알고리즘을 공부하면서 해야하니까 시간이 배로 든다. 이제는 진짜 한문제도 감지덕지.. 쉬운거 나오면 더 푸는 형식으로 진행해야 할 것 같다.

![Image](https://github.com/user-attachments/assets/ddeccc5d-6483-4d66-bbbf-ab3bb00411e9){: .align-center style="width:35%;"}

&nbsp; 자격증은 자격증대로 공부해야하고 LLM은 LLM대로 해야하고 잠을 안잘 수도 없구.. 나는 아직 무지렁이인데, 부트캠프는 2달도 안남았구.. 내가 보여줄건 꾸준함밖에 없는데.. 진짜 큰일났다.. 부트캠프 끝나면 뭐 공부할지도 고민을 해봐야할 것 같다..🫠