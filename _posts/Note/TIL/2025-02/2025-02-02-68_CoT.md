---
title:  "[TIL] 내일배움캠프 68일차_[LLM] CoT(Chain-of-Thought) Prompt" 

categories: 
    - TIL
tags: 
    - TIL
    - 내일배움캠프
    - LLM
    - CoT


toc: True
toc_sticky: True
---

![TIL](/assets/images/TIL2.png){: .align-center style="width:35%;"}

# 👀Today I Learn
## 1. Chain-of-Thought(CoT)란?
- Chain-of-Thought (CoT) Prompting은 대형 언어 모델(LLM)의 논리적 추론(reasoning) 능력을 향상시키는 프롬프팅 기법
- 기존 프롬프팅 방식은 **입력에 대해 즉시 정답을 생성(direct answer prediction)**하는 방식이었으나,
CoT 프롬프팅은 단계별 사고 과정(step-by-step reasoning)을 모델이 명시적으로 출력하도록 유도하여 추론 성능을 크게 향상시킴
- CoT는 주로 **수학 문제 해결(mathematical reasoning), 논리적 추론(logical reasoning), 상식적 추론(common sense reasoning)**과 같은 복잡한 문제에서 성능이 향상됨을 실험적으로 입증

<br>

## 2. CoT 등장 배경
### 기존 LLM의 한계
- 대형 언어 모델(예: GPT-3, PaLM-540B)은 문맥 이해와 자연어 처리에서 강력한 성능을 보였지만,
수학 문제나 논리적 추론이 필요한 문제에서는 성능이 낮음
- 특히, **단순한 Zero-shot Prompting(예제 없이 정답을 바로 출력하는 방식)**으로는 논리적으로 복잡한 문제를 해결하기 어려움

### Few-shot Prompting
- 기존에는 모델의 추론 능력을 향상시키기 위해 Few-shot Prompting(예제 몇 개를 제공하여 모델이 패턴을 학습하도록 유도하는 방식)이 사용됨
- 예를 들어, 모델에게 수학 문제와 그 풀이 과정을 포함한 몇 개의 예제를 제공한 후, 새로운 문제를 해결하도록 유도하는 방식
- 하지만 Few-shot 방식은 항상 효과적이지 않으며, 많은 예제가 필요할 수 있음

### Chain-of-Thought(CoT) Prompting
- CoT는 Few-shot 방식 없이도 단순한 프롬프트 변형만으로 모델의 논리적 사고 능력을 향상시킬 수 있음을 발견
- 예를 들어, "Let's think step by step." 같은 문장을 프롬프트에 추가하는 것만으로도 모델이 복잡한 문제를 더 정확하게 풀 수 있음이 확인

<br>

## 3. CoT 프롬프팅의 방식
### 기본 Prompting vs CoT Prompting 비교

![Image](https://github.com/user-attachments/assets/7d4573a9-7a36-4826-84a0-7ed38001a4d4){: .align-center}

<h4>(1) 기존 Zero-shot Prompting</h4>

- 기본 방식: 정답을 바로 예측

    ```
    Q: 철수가 사과 3개를 샀고, 2개를 영희에게 주었다. 철수에게 남은 사과는 몇 개인가?
    A: 1
    ```

<h4>(2) Zero-shot CoT Prompting</h4>

- CoT 방식: 중간 사고 과정을 포함하여 정답을 도출

    ```
    Q: 철수가 사과 3개를 샀고, 2개를 영희에게 주었다. 철수에게 남은 사과는 몇 개인가?
    Let's think step by step.
    철수는 처음에 3개의 사과를 가지고 있었다.
    영희에게 2개를 주었으므로, 3 - 2 = 1개가 남는다.
    따라서, 정답은 1개이다.
    ```

- CoT는 모델이 중간 사고 과정을 먼저 출력하도록 유도하여 문제 해결 능력을 향상시킴
- 프롬프트에 단순히 "Let's think step by step." 문장을 추가하는 것만으로 성능 향상 가능!

## 4. CoT 실험 결과
### 실험 환경
- 사용된 모델: GPT-3, PaLM-540B 등 대형 언어 모델
- 테스트 데이터셋
  - 수학 문제 해결: GSM8K, MultiArith
  - 논리적 추론: CommonsenseQA, StrategyQA
  - 기호적 추론: Last Letter Concatenation, Date Understanding
### 주요 결과
- GSM8K(수학 문제)에서의 정확도 비교

    |프롬프트 방식	                            |정확도(%)|
    |-------------------------------------------|:-------:|
    |기본 Zero-shot                             |17.7%    |
    |Zero-shot CoT(Let's think step by step)	|40.7%    |
    |Few-shot CoT                               |57.1%    |

    ![Image](https://github.com/user-attachments/assets/cdc92676-26c5-41ce-aeb7-0fe366dad9c8){: .align-center}

- CoT를 적용하면 기존 Zero-shot 방식 대비 성능이 최대 2~3배 향상됨
- 특히 대형 모델(100B+ 파라미터)에서 효과가 극대화됨

<br>

## 5. CoT의 핵심 발견

<h3>1. Zero-shot 환경에서도 논리적 추론 가능</h3>

- 기존에는 CoT가 Few-shot 환경에서만 효과적이라고 여겨졌음
- 하지만 이 연구들은 Zero-shot에서도 단순한 프롬프트 변형만으로 논리적 사고를 유도할 수 있음을 입증

<h3>2. 단순한 프롬프트 변경으로 성능 향상</h3>

- "Let's think step by step." 같은 간단한 문장을 추가하는 것만으로도 성능이 향상됨
- 이는 Prompt Engineering이 LLM의 성능을 극대화하는 핵심 요소임을 의미

<h3>3. 모델 크기가 클수록 효과가 극대화됨</h3>

![Image](https://github.com/user-attachments/assets/ca111315-e017-4204-9708-9e1a912bf0fc){: .align-center}

- 대형 모델(100B+ 파라미터)일수록 CoT의 효과가 더욱 강력
- 이는 LLM이 사전 학습 단계에서 이미 논리적 사고 능력을 일부 보유하고 있음을 시사

<br>

## 6. CoT의 한계 및 향후 연구 방향
### CoT의 한계
- 작은 모델에서는 효과가 미미
  - CoT는 **대형 모델(100B+ 파라미터)**에서 효과가 두드러지며, 작은 모델에서는 성능 향상이 크지 않음
- 일부 문제에서는 여전히 정답을 도출하지 못함
  - 특히 기호 조작(symbolic reasoning) 문제에서 CoT의 효과가 제한적
- 논리적 일관성이 부족할 수 있음
  - CoT가 적용된 모델도 때때로 논리적으로 맞지 않는 답변을 생성할 수 있음

### 향후 연구 방향
- Zero-shot CoT의 최적화 연구
  - "Let's think step by step."보다 더 효과적인 프롬프트 탐색
- CoT를 강화하는 학습 기법 개발
  - Fine-tuning을 통해 CoT를 자연스럽게 수행하는 모델 개발
- Self-Consistency CoT 및 Tree of Thoughts 연구
  - CoT의 한계를 극복하기 위한 추가적인 알고리즘적 접근

<br>

## 7. 결론 및 시사점
- CoT 프롬프팅이 LLM의 논리적 추론 능력을 크게 향상시킬 수 있음을 입증
- 단순한 프롬프트 변형만으로 Zero-shot에서도 성능을 높일 수 있음
- 대형 모델일수록 CoT 프롬프팅에 더 강하게 반응함
- Prompt Engineering이 LLM의 성능을 결정하는 중요한 요소임을 강조

<br>

<h3> 참고한 논문</h3>

- ["Large Language Models are Zero-Shot Reasoners" (Kojima et al., 2022)](https://proceedings.neurips.cc/paper_files/paper/2022/file/8bb0d291acd4acf06ef112099c16f326-Paper-Conference.pdf)
- ["Chain-of-Thought Prompting Elicits Reasoning in Large Language Models" (Wei et al., 2022)](https://arxiv.org/abs/2201.11903)

<br>
<br>

# 💡Today I Thought

## 오늘의 체크리스트
- [x] 알고리즘 코드카타 301-305
- [x] SQL 코드카타 101-102
- [x] Gitpage UI 조금 수정(Scroll, Navi)
- [x] LLM 메인과제
- [x] TIL 작성

## 회고
&nbsp; 오늘도 하루 마무리🤭 오늘은 코드카타가 생각보다 쉬워서 푸는데 그렇게 오래 안걸렸다! 알고리즘도 SQL도 많이 안어려웠던 좋은 하루😎 이것저것 공부할건 많은데, 시간이 모자르다. 진짜 24시간이 모자란 기분🥹 하루가.. 48시간이면 좋겠어요...😫